{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk HTML Ingestion with ColPali and Astra Late Interaction Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "**Python version**: 3.12+ \n",
    "\n",
    "### Packages:\n",
    "\n",
    "**For connecting to AstraDB**:\n",
    "`astrapy==2.0.0rc`\n",
    "\n",
    "**For convenient Late Interaction processing**:\n",
    "`astra-multivector[late-interaction]`\n",
    "\n",
    "**For converting HTML files to images**:\n",
    "`weasyprint`\n",
    "`pdf2image`\n",
    "\n",
    "Alternatively you could simply install `astra-multivector[all]` and this will download the requirements necessary for this specific notebook, but there may be other dependencies that you will find unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: faiss must be imported for indexing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071f5f81768a44e0b5193b36374d04aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from astrapy import AsyncDatabase, DataAPIClient\n",
    "from astrapy.api_options import APIOptions\n",
    "\n",
    "from astra_multivector.late_interaction import ColPaliModel, LateInteractionPipeline\n",
    "\n",
    "\n",
    "# Load Environment Variables\n",
    "load_dotenv()\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_API_ENDPOINT = os.getenv(\"ASTRA_DB_API_ENDPOINT\")\n",
    "\n",
    "\n",
    "from astrapy import DataAPIClient\n",
    "from astrapy.utils.api_options import APIOptions, TimeoutOptions\n",
    "\n",
    "# Configure TimeoutOptions for optimized connection handling\n",
    "timeout_options = TimeoutOptions(\n",
    "    request_timeout_ms=30000,\n",
    "    general_method_timeout_ms=60000,\n",
    "    table_admin_timeout_ms=60000\n",
    ")\n",
    "\n",
    "# Create the client with optimized connection settings\n",
    "astra_client: DataAPIClient = DataAPIClient(\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    api_options=APIOptions(\n",
    "        timeout_options=timeout_options,\n",
    "        database_additional_headers={\n",
    "            \"Connection\": \"keep-alive\"\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "db: AsyncDatabase = astra_client.get_async_database(api_endpoint=ASTRA_DB_API_ENDPOINT)\n",
    "\n",
    "\n",
    "# Initialize ColPali Model\n",
    "model = ColPaliModel(\n",
    "    model_name=\"vidore/colpali-v1.3\",\n",
    "    device=\"mps\",\n",
    ")\n",
    "\n",
    "# Initialize Late Interaction Pipeline\n",
    "pipeline = LateInteractionPipeline(\n",
    "    db=db,\n",
    "    model=model,\n",
    "    base_table_name=\"colpali_table\",\n",
    "    doc_pool_factor=10,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger astra_multivector.late_interaction (DEBUG)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "def setup_logging(level=logging.DEBUG):\n",
    "    root_logger = logging.getLogger()\n",
    "    for handler in root_logger.handlers[:]:\n",
    "        root_logger.removeHandler(handler)\n",
    "    \n",
    "    root_logger.setLevel(level)\n",
    "    \n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setLevel(level)\n",
    "    \n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    console_handler.setFormatter(formatter)\n",
    "    \n",
    "    root_logger.addHandler(console_handler)\n",
    "    \n",
    "    return root_logger\n",
    "\n",
    "def config_module_logging(module_name, level=logging.DEBUG):\n",
    "    logger = logging.getLogger(module_name)\n",
    "    logger.setLevel(level)\n",
    "    return logger\n",
    "\n",
    "logger = setup_logging(logging.DEBUG)\n",
    "\n",
    "config_module_logging('astra_multivector.late_interaction', logging.DEBUG)\n",
    "\n",
    "#config_module_logging('astrapy', logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML to Image Pipeline\n",
    "\n",
    "ColPali requires the input documents to be images. Furthermore, the training method treated PDF pages as individual input documents, so if your HTML page is large it will be beneficial to convert it into a multi-page PDF and vectorize each page as an image.\n",
    "\n",
    "ColPali generators 1024 + 7 vectors for each page-image. The 1024 vectors are akin to the token-wise embeddings from ColBERT, the underlying Vision Transformer partitions the image into a 32 x 32 grid. The other 7 vectors encode contextual information derived from ColPali’s special tokens (e.g., for the beginning of the sequence, and task-specific instructions like “Describe the image”).\n",
    "\n",
    "We can use pooling to reduce the number of vectors we return per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import PosixPath\n",
    "from PIL import Image\n",
    "from uuid import UUID\n",
    "from typing import Dict, Generator, List, Optional, Union\n",
    "\n",
    "from weasyprint import HTML\n",
    "from pdf2image import convert_from_bytes\n",
    "\n",
    "\n",
    "def html_to_pages(\n",
    "    html_path: Optional[PosixPath] = None,\n",
    "    html_content: Optional[str] = None,\n",
    "    dpi: int = 200\n",
    ") -> List[Image.Image]:\n",
    "    \"\"\"\n",
    "    Convert HTML to multiple page images\n",
    "    \n",
    "    Args:\n",
    "        html_path: Path to HTML file\n",
    "        html_content: HTML content as string\n",
    "        dpi: Resolution for the images\n",
    "        \n",
    "    Returns:\n",
    "        List of PIL Images, one per page\n",
    "    \"\"\"\n",
    "    if html_path:\n",
    "        document = HTML(filename=html_path)\n",
    "    elif html_content:\n",
    "        document = HTML(string=html_content)\n",
    "    else:\n",
    "        raise ValueError(\"Either html_path or html_content must be provided\")\n",
    "    \n",
    "    pdf_bytes = document.write_pdf()\n",
    "    \n",
    "    images: List[Image.Image] = convert_from_bytes(pdf_bytes, dpi=dpi)\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def html_page_generator(\n",
    "    directory_path: PosixPath\n",
    ") -> Generator[Dict[str, Union[Image.Image, str]], None, None]:\n",
    "    \"\"\"\n",
    "    Generator that yields dictionaries containing page images for each HTML file.\n",
    "    \n",
    "    Args:\n",
    "        directory_path: Path object pointing to the directory to search\n",
    "        \n",
    "    Yields:\n",
    "        Dict with content (page image) and image_url (source HTML path)\n",
    "    \"\"\"\n",
    "    html_files: Generator[PosixPath, None, None] = directory_path.rglob(\"*html\")\n",
    "    \n",
    "    for html_path in html_files:\n",
    "        try:\n",
    "            page_images: List[Image.Image] = html_to_pages(html_path)\n",
    "            \n",
    "            for page_image in page_images:\n",
    "                yield {\n",
    "                    \"content\": page_image,\n",
    "                    \"image_url\": str(html_path),\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {html_path}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "\n",
    "async def bulk_index_html_directory(\n",
    "    pipeline: LateInteractionPipeline,\n",
    "    directory_path: PosixPath,\n",
    "    batch_size: int = 5,\n",
    "    concurrency: int = 3) -> List[UUID]:\n",
    "    \"\"\"\n",
    "    Index HTML files from a directory into the late interaction pipeline.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: LateInteractionPipeline instance\n",
    "        directory_path: Path to directory containing HTML files\n",
    "        batch_size: Number of pages to process in a batch\n",
    "        concurrency: Maximum number of concurrent embedding operations\n",
    "    \n",
    "    Returns:\n",
    "        List of document IDs indexed\n",
    "    \"\"\"\n",
    "    page_dicts = html_page_generator(directory_path)\n",
    "    all_doc_ids = []\n",
    "    \n",
    "    batch = []\n",
    "    for page_dict in page_dicts:\n",
    "        print(f\"Indexing document {page_dict['image_url']} with {page_dict['content'].size}\")\n",
    "        batch.append(page_dict)\n",
    "        \n",
    "        if len(batch) >= batch_size:\n",
    "            doc_ids = await pipeline.bulk_index_documents(\n",
    "                batch, \n",
    "                embedding_concurrency=concurrency\n",
    "            )\n",
    "            all_doc_ids.extend(doc_ids)\n",
    "            \n",
    "            batch = []\n",
    "            print(f\"Indexed {len(doc_ids)} pages, total so far: {len(all_doc_ids)}\")\n",
    "    \n",
    "    if batch:\n",
    "        doc_ids = await pipeline.bulk_index_documents(\n",
    "            batch, \n",
    "            embedding_concurrency=concurrency\n",
    "        )\n",
    "        all_doc_ids.extend(doc_ids)\n",
    "        print(f\"Indexed {len(doc_ids)} pages, total: {len(all_doc_ids)}\")\n",
    "    \n",
    "    return all_doc_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest HTML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, PosixPath\n",
    "\n",
    "\n",
    "file_directory: PosixPath = Path(\"/Users/brian.ogrady/src/python3/astra-multivector/examples/notebooks/\")\n",
    "\n",
    "await bulk_index_html_directory(\n",
    "    pipeline=pipeline,\n",
    "    directory_path=file_directory,\n",
    "    batch_size=1,\n",
    "    concurrency=None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Search Queries\n",
    "\n",
    "Below is a small experiment for measuring the latencies against a list of input questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timing Statistics:\n",
      "Average time: 0.431 seconds\n",
      "Min time: 0.371 seconds\n",
      "Max time: 1.638 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "questions = pd.read_csv(os.getenv(\"QUESTIONS_FILE_PATH\"))\n",
    "questions = questions[\"Questions\"].tolist()\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "async def measure_search_times(pipeline, questions: List[str]) -> List[Tuple[str, float, List]]:\n",
    "    \"\"\"\n",
    "    Measure search execution time for each question.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: LateInteractionPipeline instance\n",
    "        questions: List of questions to search\n",
    "        \n",
    "    Returns:\n",
    "        List of tuples containing (question, execution_time, search_results)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for question in questions:\n",
    "        start_time = asyncio.get_event_loop().time()\n",
    "        search_results = await pipeline.search(\n",
    "            query=\"What are the monthly access charges for 2 lines with autopay and without autopay?\",\n",
    "            k=5,\n",
    "            n_ann_tokens=20,\n",
    "        )\n",
    "        end_time = asyncio.get_event_loop().time()\n",
    "        \n",
    "        execution_time = end_time - start_time\n",
    "        results.append((question, execution_time, search_results))\n",
    "    \n",
    "    return results\n",
    "\n",
    "search_results = await measure_search_times(pipeline, questions)\n",
    "\n",
    "\n",
    "times = [t for _, t, _ in search_results]\n",
    "print(\"\\nTiming Statistics:\")\n",
    "print(f\"Average time: {sum(times)/len(times):.3f} seconds\")\n",
    "print(f\"Min time: {min(times):.3f} seconds\")\n",
    "print(f\"Max time: {max(times):.3f} seconds\")\n",
    "print(f\"Quantiles: {np.quantile(times, [0.5, 0.75, 0.9, 0.95, 0.99])}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
